{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"name":"algo.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"PWOqkSU_i0XK","colab_type":"text"},"source":["**<h1> Algorithmic Trading Using Deep Q Learning**"]},{"cell_type":"code","metadata":{"id":"l8aMBvlEi0XT","colab_type":"code","colab":{}},"source":["import time\n","import copy\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from plotly import tools\n","from plotly.graph_objs import *\n","from plotly.offline import init_notebook_mode, iplot, iplot_mpl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XYe8ehMOjLfI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1588425876080,"user_tz":-330,"elapsed":3634,"user":{"displayName":"Ning Mah Lun","photoUrl":"","userId":"14854885870819313728"}},"outputId":"a79ca35b-a029-411b-df44-3def674f0e06"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WNXley6iVA_l","colab_type":"text"},"source":["**<h2>Loading Dataset**"]},{"cell_type":"code","metadata":{"id":"WU1sMQAmi0Xb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"status":"ok","timestamp":1588425884520,"user_tz":-330,"elapsed":1271,"user":{"displayName":"Ning Mah Lun","photoUrl":"","userId":"14854885870819313728"}},"outputId":"5aba295c-4118-441a-a29e-ee8b65102dd0"},"source":["data = pd.read_csv('drive/My Drive/MSFT.csv')\n","data['Date'] = pd.to_datetime(data['Date'])\n","data = data.set_index('Date')\n","print(data.index.min(), data.index.max())\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2010-01-04 00:00:00 2019-12-31 00:00:00\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Open</th>\n","      <th>High</th>\n","      <th>Low</th>\n","      <th>Close</th>\n","      <th>Adj Close</th>\n","      <th>Volume</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2010-01-04</th>\n","      <td>30.620001</td>\n","      <td>31.100000</td>\n","      <td>30.590000</td>\n","      <td>30.950001</td>\n","      <td>24.294369</td>\n","      <td>38409100</td>\n","    </tr>\n","    <tr>\n","      <th>2010-01-05</th>\n","      <td>30.850000</td>\n","      <td>31.100000</td>\n","      <td>30.639999</td>\n","      <td>30.959999</td>\n","      <td>24.302216</td>\n","      <td>49749600</td>\n","    </tr>\n","    <tr>\n","      <th>2010-01-06</th>\n","      <td>30.879999</td>\n","      <td>31.080000</td>\n","      <td>30.520000</td>\n","      <td>30.770000</td>\n","      <td>24.153070</td>\n","      <td>58182400</td>\n","    </tr>\n","    <tr>\n","      <th>2010-01-07</th>\n","      <td>30.629999</td>\n","      <td>30.700001</td>\n","      <td>30.190001</td>\n","      <td>30.450001</td>\n","      <td>23.901886</td>\n","      <td>50559700</td>\n","    </tr>\n","    <tr>\n","      <th>2010-01-08</th>\n","      <td>30.280001</td>\n","      <td>30.879999</td>\n","      <td>30.240000</td>\n","      <td>30.660000</td>\n","      <td>24.066734</td>\n","      <td>51197400</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 Open       High        Low      Close  Adj Close    Volume\n","Date                                                                       \n","2010-01-04  30.620001  31.100000  30.590000  30.950001  24.294369  38409100\n","2010-01-05  30.850000  31.100000  30.639999  30.959999  24.302216  49749600\n","2010-01-06  30.879999  31.080000  30.520000  30.770000  24.153070  58182400\n","2010-01-07  30.629999  30.700001  30.190001  30.450001  23.901886  50559700\n","2010-01-08  30.280001  30.879999  30.240000  30.660000  24.066734  51197400"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"opkWLie7i0Xg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1588425886446,"user_tz":-330,"elapsed":1246,"user":{"displayName":"Ning Mah Lun","photoUrl":"","userId":"14854885870819313728"}},"outputId":"1f7bfedf-a636-47ac-818d-e493bcf95bc7"},"source":["date_split = '2016-01-01'\n","train = data[:date_split]\n","test = data[date_split:]\n","len(train),len(test)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1510, 1006)"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"Fbl-U65TkOzF","colab_type":"text"},"source":["**MDP Environment**"]},{"cell_type":"code","metadata":{"id":"hSQCZudSi0Xr","colab_type":"code","colab":{}},"source":["class Environment1:\n","    \n","    def __init__(self, data, history_t=90, cash_in_hand = 1000):\n","        self.data = data\n","        self.history_t = history_t\n","        self.reset()\n","        self.cash_in_hand = cash_in_hand\n","        \n","    def reset(self):\n","        self.t = 0\n","        self.done = False\n","        self.profits = 0\n","        self.positions = []\n","        self.position_value = 0\n","        self.history = [0 for _ in range(self.history_t)]\n","        return [self.position_value] + self.history # obs\n","    \n","    def step(self, act):\n","        reward = -1\n","        \n","        # act = 0: stay, 1: buy, 2: sell\n","        if act == 1:\n","          if self.cash_in_hand < self.data.iloc[self.t,:]['Close']:\n","            reward = -100\n","          self.positions.append(self.data.iloc[self.t, :]['Close'])\n","          self.cash_in_hand -= self.data.iloc[self.t, :]['Close']\n","\n","        elif act == 2: \n","            if len(self.positions) == 0:\n","                reward = -100\n","            else:\n","                profits = 0\n","                for p in self.positions:\n","                    profits += (self.data.iloc[self.t, :]['Close'] - p)\n","                    self.cash_in_hand += self.data.iloc[self.t, :]['Close']\n","                reward += profits\n","                self.profits += profits\n","                self.positions = []\n","        \n","        # set next time\n","        self.t += 1\n","        \n","        self.position_value = 0\n","        for p in range(len(self.positions)):\n","            self.position_value += (self.data.iloc[self.t, :]['Close'] - self.positions[p])\n","        self.history.pop(0)\n","        self.history.append(self.data.iloc[self.t, :]['Close'] - self.data.iloc[(self.t-1), :]['Close'])\n","        if (self.t==len(self.data)-1):\n","            self.done=True\n","        # clipping reward\n","        if reward > 0:\n","            reward = 1\n","        elif reward < 0:\n","            reward = -1\n","        #print (\"t={%d}, done={%str}\"%(self.t,self.done))\n","        return [self.position_value] + self.history, reward, self.cash_in_hand, self.done # obs, reward, done\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wFGf4oivi0Xv","colab_type":"code","colab":{}},"source":["env = Environment1(train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TukV3G76kaQm","colab_type":"text"},"source":["**<h2>Deep Q-Network</h2>**<br>\n","The model involves a 3 layer neural network with hidden_size = 100 (hyperparmater)"]},{"cell_type":"code","metadata":{"id":"7P_BnI4ui0Xz","colab_type":"code","colab":{}},"source":["#def train_dqn(env):\n","class Q_Network(nn.Module):\n","  def __init__(self,obs_len,hidden_size,actions_n):\n","    super(Q_Network,self).__init__()\n","\n","    self.fc_val = nn.Sequential(\n","        nn.Linear(obs_len, hidden_size),\n","        nn.ReLU(),\n","        nn.Linear(hidden_size, hidden_size),\n","        nn.ReLU(),\n","        nn.Linear(hidden_size, actions_n),\n","        nn.Softmax(dim=1)\n","    )\n","\n","  def forward(self,x):\n","    h = self.fc_val(x)\n","    return (h)            "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iRzAdtZjki_b","colab_type":"text"},"source":["**Setting up parameters**"]},{"cell_type":"code","metadata":{"id":"OmKGp2j8i0X2","colab_type":"code","colab":{}},"source":["hidden_size=100\n","input_size=env.history_t+1\n","output_size=3\n","USE_CUDA = False\n","LR = 0.001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G8avypZ1i0X5","colab_type":"code","colab":{}},"source":["Q = Q_Network(input_size, hidden_size, output_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Za101fgLi0X-","colab_type":"code","colab":{}},"source":["Q_ast = copy.deepcopy(Q)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_hJCixNi0YB","colab_type":"code","colab":{}},"source":["if USE_CUDA:\n","    Q = Q.cuda()\n","loss_function = nn.MSELoss()\n","\n","#defineing the optimizer\n","optimizer = optim.Adam(list(Q.parameters()), lr=LR)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CVENQo5Okpne","colab_type":"text"},"source":[" **<h2>Deep Q-learning</h2>**<br>\n","\n","---\n"," \n","1.   Initialize replay memory capacity\n","2.   Initialize the network with random weights\n","3.   For each time step: \n","\n",">*   Select an action (via exploration or exploitation)\n",">*   Execute selected action in an emulator\n",">*   Observe reward and next state\n",">*   Store experience in replay memory\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"EnlT8aNmi0YE","colab_type":"code","colab":{}},"source":["epoch_num = 50\n","step_max = len(env.data)-1\n","memory_size = 200\n","batch_size = 50\n","gamma = 0.97"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XGJ5eDVyi0YK","colab_type":"code","colab":{}},"source":["memory = []  #Replay Memory\n","total_step = 0\n","total_rewards = []\n","total_losses = []\n","epsilon = 1.0  #exploration rate\n","epsilon_decrease = 1e-3\n","epsilon_min = 0.1\n","start_reduce_epsilon = 200\n","train_freq = 10\n","update_q_freq = 20\n","gamma = 0.97  #discount rate\n","show_log_freq = 5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ItIb3XSYi0YN","colab_type":"code","colab":{}},"source":["start = time.time()\n","for epoch in range(epoch_num):\n","\n","    pobs = env.reset()\n","    step = 0\n","    done = False\n","    total_reward = 0\n","    total_loss = 0\n","    cash_in_hand = 1000\n","\n","    while not done and step < step_max:\n","\n","        # select act using exploration\n","        pact = np.random.randint(3)\n","\n","        # select act using exploitation\n","        if np.random.rand() > epsilon:\n","            pact = Q(torch.from_numpy(np.array(pobs, dtype=np.float32).reshape(1, -1)))\n","            pact = np.argmax(pact.data)\n","            pact = pact.numpy()\n","\n","        # act\n","        obs, reward, cash_in_hand, done = env.step(pact)\n","\n","        # add memory\n","        memory.append((pobs, pact, reward, obs, cash_in_hand, done))\n","        if len(memory) > memory_size:\n","            memory.pop(0)\n","\n","        # train or update q\n","        if len(memory) == memory_size:\n","            if total_step % train_freq == 0:\n","                shuffled_memory = np.random.permutation(memory)   #taking random samples in order to break the correlation between consecutive samples\n","                memory_idx = range(len(shuffled_memory))\n","                for i in memory_idx[::batch_size]:\n","                    batch = np.array(shuffled_memory[i:i+batch_size])\n","                    b_pobs = np.array(batch[:, 0].tolist(), dtype=np.float32).reshape(batch_size, -1)\n","                    b_pact = np.array(batch[:, 1].tolist(), dtype=np.int32)\n","                    b_reward = np.array(batch[:, 2].tolist(), dtype=np.int32)\n","                    b_obs = np.array(batch[:, 3].tolist(), dtype=np.float32).reshape(batch_size, -1)\n","                    b_cash_in_hand = np.array(batch[:,4].tolist(), dtype = np.float32)\n","                    b_done = np.array(batch[:, 5].tolist(), dtype=np.bool)\n","\n","                    q = Q(torch.from_numpy(b_pobs))\n","                    q_ = Q_ast(torch.from_numpy(b_obs))\n","                    maxq = np.max(q_.data.numpy(),axis=1)\n","                    target = copy.deepcopy(q.data)\n","                    for j in range(batch_size):\n","                        target[j, b_pact[j]] = b_reward[j]+gamma*maxq[j]*(not b_done[j])   #Bellman equation\n","                    Q.zero_grad() #clear the previous gradients\n","                    loss = loss_function(q, target) #compute loss\n","                    total_loss += loss.data.item()\n","                    loss.backward() #compute gradients\n","                    optimizer.step()  #adjust weights\n","                    \n","            if total_step % update_q_freq == 0:\n","                Q_ast = copy.deepcopy(Q)\n","                \n","            # update epsilon\n","            if epsilon > epsilon_min and total_step > start_reduce_epsilon:\n","                epsilon -= epsilon_decrease\n","\n","            # next step\n","            total_reward += reward\n","            pobs = obs\n","            step += 1\n","            total_step += 1\n","\n","        total_rewards.append(total_reward)\n","        total_losses.append(total_loss)\n","\n","        if (epoch+1) % show_log_freq == 0:\n","            log_reward = sum(total_rewards[((epoch+1)-show_log_freq):])/show_log_freq\n","            log_loss = sum(total_losses[((epoch+1)-show_log_freq):])/show_log_freq\n","            elapsed_time = time.time()-start\n","            print('\\t'.join(map(str, [epoch+1, epsilon, total_step, log_reward, log_loss, elapsed_time])))\n","            start = time.time()\n","            \n","#return Q, total_losses, total_rewards"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6cMDOE4kt84","colab_type":"text"},"source":["**Testing**"]},{"cell_type":"code","metadata":{"id":"WE_bNLawi0YR","colab_type":"code","colab":{}},"source":["test_env = Environment1(test)\n","pobs = test_env.reset()\n","test_acts = []\n","test_rewards = []\n","current_cash_in_hand = []\n","\n","for _ in range(len(test_env.data)-1):\n","    \n","    pact = Q(torch.from_numpy(np.array(pobs, dtype=np.float32).reshape(1, -1)))\n","    pact = np.argmax(pact.data)\n","    test_acts.append(pact.item())\n","            \n","    obs, reward, cash_in_hand, done = test_env.step(pact.numpy())\n","    test_rewards.append(reward)\n","    current_cash_in_hand.append(cash_in_hand)\n","\n","    pobs = obs\n","        \n","test_profits = test_env.profits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-KtMzZ-Wi0YU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1588436609071,"user_tz":-330,"elapsed":433537,"user":{"displayName":"Ning Mah Lun","photoUrl":"","userId":"14854885870819313728"}},"outputId":"f3ad2556-7ee9-4c71-ba01-c904480a7acd"},"source":["test_profits"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["801.5499329999996"]},"metadata":{"tags":[]},"execution_count":207}]},{"cell_type":"code","metadata":{"id":"vvW7BhaGuNje","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}